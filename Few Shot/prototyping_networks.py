# -*- coding: utf-8 -*-
"""Prototyping_Networks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E5l6CMmYdR_MPABfUqTG9KCUeNIx3175
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

class FewShotBinaryDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.class_names = ['Mild', 'Severe']
        self.class_to_idx = {'Mild': 0, 'Severe': 1}
        self.tasks = self._get_tasks(root_dir)

    def _get_tasks(self, root_dir):
        tasks = []
        for task_dir in os.listdir(root_dir):
            task_path = os.path.join(root_dir, task_dir)
            if os.path.isdir(task_path):
                support_path = os.path.join(task_path, "Support")
                query_path = os.path.join(task_path, "Query")
                tasks.append({
                    "support": self._get_images(support_path),
                    "query": self._get_images(query_path)
                })
        return tasks

    def _get_images(self, folder_path):
        images = []
        for class_folder in os.listdir(folder_path):
            class_path = os.path.join(folder_path, class_folder)
            if os.path.isdir(class_path):
                for img_file in os.listdir(class_path):
                    img_path = os.path.join(class_path, img_file)
                    images.append({
                        "image": img_path,
                        "label": self.class_to_idx[class_folder]
                    })
        return images

    def __len__(self):
        return len(self.tasks)

    def __getitem__(self, idx):
        task = self.tasks[idx]
        support_images = [(Image.open(item["image"]), item["label"]) for item in task["support"]]
        query_images = [(Image.open(item["image"]), item["label"]) for item in task["query"]]

        if self.transform:
            support_images = [(self.transform(img), label) for img, label in support_images]
            query_images = [(self.transform(img), label) for img, label in query_images]

        return support_images, query_images

class PrototypicalNetwork(nn.Module):
    def __init__(self, embedding_dim):
        super(PrototypicalNetwork, self).__init__()
        self.encoder = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        self.encoder.fc = nn.Linear(self.encoder.fc.in_features, embedding_dim)

    def forward(self, support_images, support_labels, query_images):

        support_embeddings = self.encoder(support_images)
        query_embeddings = self.encoder(query_images)


        prototypes = []
        for class_idx in range(2):
            class_embeddings = support_embeddings[support_labels == class_idx]
            class_prototype = class_embeddings.mean(dim=0)
            prototypes.append(class_prototype)

        prototypes = torch.stack(prototypes)


        dists = torch.cdist(query_embeddings, prototypes)


        output = F.log_softmax(-dists, dim=1)

        return output

def train_task(model, support_set, query_set, optimizer, criterion):
    model.train() if optimizer else model.eval()

    support_images, support_labels = zip(*support_set)
    query_images, query_labels = zip(*query_set)

    support_images = torch.stack([img.squeeze(0) for img in support_images]).to(device)
    support_labels = torch.tensor(support_labels).to(device)
    query_images = torch.stack([img.squeeze(0) for img in query_images]).to(device)
    query_labels = torch.tensor(query_labels).to(device)


    output = model(support_images, support_labels, query_images)
    loss = criterion(output, query_labels)

    if optimizer:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    _, predicted = torch.max(output.data, 1)
    accuracy = (predicted == query_labels).float().mean()

    return loss.item(), accuracy.item()

def train(model, train_loader, val_loader, num_epochs, learning_rate, weight_decay, patience):
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    criterion = nn.NLLLoss()

    best_val_loss = np.inf
    patience_counter = 0

    for epoch in range(num_epochs):
        train_loss, train_accuracy = 0.0, 0.0
        val_loss, val_accuracy = 0.0, 0.0


        for support_set, query_set in train_loader:
            loss, accuracy = train_task(model, support_set, query_set, optimizer, criterion)
            train_loss += loss
            train_accuracy += accuracy


        with torch.no_grad():
            for support_set, query_set in val_loader:
                loss, accuracy = train_task(model, support_set, query_set, None, criterion)
                val_loss += loss
                val_accuracy += accuracy

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)

        print(f'Epoch {epoch+1}/{num_epochs}, '
              f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')


        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), "best_model.pth")
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print("Early stopping triggered")
            break

def test(model, test_loader):
    model.eval()
    all_preds, all_labels = [], []

    with torch.no_grad():
        for support_set, query_set in test_loader:
            support_images, support_labels = zip(*support_set)
            query_images, query_labels = zip(*query_set)

            support_images = torch.stack([img.squeeze(0) for img in support_images]).to(device)
            support_labels = torch.tensor(support_labels).to(device)
            query_images = torch.stack([img.squeeze(0) for img in query_images]).to(device)
            query_labels = torch.tensor(query_labels).to(device)

            output = model(support_images, support_labels, query_images)
            _, predicted = torch.max(output.data, 1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(query_labels.cpu().numpy())


    print("Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=['Mild', 'Severe']))


    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Mild', 'Severe'], yticklabels=['Mild', 'Severe'])
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.title("Confusion Matrix")
    plt.show()

embedding_dim = 64
model =PrototypicalNetwork(embedding_dim=embedding_dim)



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)


transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

train_dataset = FewShotBinaryDataset(root_dir="/content/drive/MyDrive/fewshot Dataset binary2/Meta-Training", transform=transform)
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)

val_dataset = FewShotBinaryDataset(root_dir="/content/drive/MyDrive/fewshot Dataset binary2/Meta-Validation", transform=transform)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)

test_dataset = FewShotBinaryDataset(root_dir="/content/drive/MyDrive/fewshot Dataset binary2/Meta-Testing", transform=transform)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

train(model, train_loader, val_loader, num_epochs=200, learning_rate=0.000001, weight_decay=1e-4, patience=70)
model.load_state_dict(torch.load("best_model.pth"))
test(model, test_loader)



















