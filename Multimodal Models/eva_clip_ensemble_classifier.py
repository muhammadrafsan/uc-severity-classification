# -*- coding: utf-8 -*-
"""EVA_CLIP_Text_based_Ensemble_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DA1DFkUN1W8q_U8Bs8J5zeJwpNQTdMzY
"""



# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/baaivision/EVA.git
# %cd EVA/EVA-CLIP
!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
!pip install timm ftfy opt-einsum
!pip install xformers

import sys
sys.path.append('/content/EVA/EVA-CLIP/rei')

import torch
from eva_clip import create_model_and_transforms, get_tokenizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import VotingClassifier

model_name = "EVA02-CLIP-B-16"
model, _, preprocess = create_model_and_transforms(model_name, pretrained='eva_clip', force_custom_clip=True)
tokenizer = get_tokenizer(model_name)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)
print(device)

class_descriptions_split = [
    [
        "Mild Ulcerative Colitis: The colon appears relatively healthy with a reddish or pinkish hue, indicating low-grade inflammation.",
        "The mucosal surface is generally smooth, with a visible vascular pattern. Small superficial erosions may be present, but ulcerations are shallow and scattered.",
        "There is little to no bleeding, and the overall appearance reflects minimal damage confined to the mucosa."
    ],
    [
        "Severe Ulcerative Colitis: The colon takes on a deep red or purplish color, indicating severe inflammation.",
        "The surface is irregular, with prominent ulcerations that span large areas and reach deeper layers of the colon.",
        "Blood vessels are no longer visible due to thickened tissue, and bleeding often occurs spontaneously or upon contact."
    ]
]

mild_text = " ".join(class_descriptions_split[0])
severe_text = " ".join(class_descriptions_split[1])
text_tokens_mild = tokenizer([mild_text])
text_tokens_severe = tokenizer([severe_text])

text_inputs_mild = text_tokens_mild.to(device)
text_inputs_severe = text_tokens_severe.to(device)

with torch.no_grad():
    text_features_mild = model.encode_text(text_inputs_mild)
    text_features_severe = model.encode_text(text_inputs_severe)

text_features_mild /= text_features_mild.norm(dim=-1, keepdim=True)
text_features_severe /= text_features_severe.norm(dim=-1, keepdim=True)

print("Text features for mild and severe classes are encoded and normalized.")

from google.colab import drive
drive.mount('/content/drive')

import os
from sklearn.model_selection import train_test_split
from PIL import Image
import numpy as np

dataset_dir = "/content/drive/MyDrive/Binary Ulceraive Colitis"
mild_images_dir = os.path.join(dataset_dir, "mild")
severe_images_dir = os.path.join(dataset_dir, "severe")
mild_images = [os.path.join(mild_images_dir, img) for img in os.listdir(mild_images_dir) if img.endswith('.jpg')]
severe_images = [os.path.join(severe_images_dir, img) for img in os.listdir(severe_images_dir) if img.endswith('.jpg')]
all_images = mild_images + severe_images
labels = [0] * len(mild_images) + [1] * len(severe_images)
train_images, test_images, train_labels, test_labels = train_test_split(all_images, labels, test_size=0.2, stratify=labels, random_state=42)

def encode_images(image_paths):
    image_features = []
    for img_path in image_paths:
        image = Image.open(img_path)
        image = preprocess(image).unsqueeze(0).to(device)
        with torch.no_grad():
            image_feature = model.encode_image(image)
            image_features.append(image_feature)
    return torch.cat(image_features, dim=0)
train_features = encode_images(train_images).cpu().numpy()
test_features = encode_images(test_images).cpu().numpy()

def combine_features_with_text(image_features, labels, text_features_mild, text_features_severe):
    combined_features = []
    for img_feat, label in zip(image_features, labels):
        if label == 0:  # Mild
            combined_features.append(np.concatenate([img_feat, text_features_mild.cpu().numpy().flatten()]))
        else:  # Severe
            combined_features.append(np.concatenate([img_feat, text_features_severe.cpu().numpy().flatten()]))
    return np.array(combined_features)

train_features_combined = combine_features_with_text(train_features, train_labels, text_features_mild, text_features_severe)
test_features_combined = combine_features_with_text(test_features, test_labels, text_features_mild, text_features_severe)

from sklearn.model_selection import GridSearchCV, train_test_split

knn_param_grid = {
    'n_neighbors': [3, 5, 7, 9],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

knn = KNeighborsClassifier()
knn_grid_search = GridSearchCV(knn, knn_param_grid, cv=5, scoring='accuracy', verbose=1)
knn_grid_search.fit(train_features_combined, train_labels)
best_knn = knn_grid_search.best_estimator_
print(f"Best KNN parameters: {knn_grid_search.best_params_}")

svm_param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

svm = SVC(probability=True)
svm_grid_search = GridSearchCV(svm, svm_param_grid, cv=5, scoring='accuracy', verbose=1)
svm_grid_search.fit(train_features_combined, train_labels)
best_svm = svm_grid_search.best_estimator_
print(f"Best SVM parameters: {svm_grid_search.best_params_}")

rf_param_grid = {
    'n_estimators': [100, 200, 300, 400, 500, 600],
    'max_depth': [None, 10, 20, 30, 40, 50, 60],
    'min_samples_split': [2, 5, 10]
}

rf = RandomForestClassifier(random_state=42)
rf_grid_search = GridSearchCV(rf, rf_param_grid, cv=5, scoring='accuracy', verbose=1)
rf_grid_search.fit(train_features_combined, train_labels)
best_rf = rf_grid_search.best_estimator_
print(f"Best Random Forest parameters: {rf_grid_search.best_params_}")

ensemble = VotingClassifier(estimators=[
    ('knn', best_knn),
    ('svm', best_svm),
    ('rf', best_rf)
], voting='soft')
ensemble.fit(train_features_combined, train_labels)

predicted_labels = ensemble.predict(test_features_combined)

accuracy = accuracy_score(test_labels, predicted_labels)
print(f"Test accuracy (tuned ensemble model): {accuracy * 100:.2f}%")

conf_matrix = confusion_matrix(test_labels, predicted_labels)
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Mild", "Severe"], yticklabels=["Mild", "Severe"])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix (Tuned Ensemble)')
plt.show()

"""# **STACK Classifier**"""

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

meta_classifier = LogisticRegression()

stacking_clf = StackingClassifier(
    estimators=[
        ('knn', best_knn),
        ('svm', best_svm),
        ('rf', best_rf)
    ],
    final_estimator=meta_classifier,
    cv=5
)

stacking_clf.fit(train_features, train_labels)

predicted_labels = stacking_clf.predict(test_features)

accuracy = accuracy_score(test_labels, predicted_labels)
print(f"Test accuracy (stacking classifier): {accuracy * 100:.2f}%")

