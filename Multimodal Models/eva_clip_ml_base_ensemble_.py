# -*- coding: utf-8 -*-
"""EVA CLip Ensemble .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sD3aDXPp6OtHFUamENLGlMvbD1kXjyVG
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone the EVA repository and set up the environment
!git clone https://github.com/baaivision/EVA.git
# %cd EVA/EVA-CLIP

# Install specific PyTorch version and torchvision with CUDA support
!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

# Install additional required libraries for EVA-CLIP
!pip install timm ftfy opt-einsum

# Install xformers for memory-efficient transformers
!pip install xformers

import sys
sys.path.append('/content/EVA/EVA-CLIP/rei')

import torch
from eva_clip import create_model_and_transforms, get_tokenizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import classification_report
import torch

from PIL import Image
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import classification_report
import numpy as np
import os

import time

model_name = "EVA02-CLIP-B-16"

model, _, preprocess = create_model_and_transforms(model_name, pretrained='eva_clip', force_custom_clip=True)
tokenizer = get_tokenizer(model_name)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

from google.colab import drive
drive.mount('/content/drive')

dataset_dir = "/content/drive/MyDrive/Binary Ulceraive Colitis"
mild_images_dir = os.path.join(dataset_dir, "mild")
severe_images_dir = os.path.join(dataset_dir, "severe")


mild_images = [os.path.join(mild_images_dir, img) for img in os.listdir(mild_images_dir) if img.endswith('.jpg')]
severe_images = [os.path.join(severe_images_dir, img) for img in os.listdir(severe_images_dir) if img.endswith('.jpg')]


all_images = mild_images + severe_images
labels = [0] * len(mild_images) + [1] * len(severe_images)


train_images, test_images, train_labels, test_labels = train_test_split(all_images, labels, test_size=0.2, stratify=labels, random_state=42)

def encode_images(image_paths):
    image_features = []
    for img_path in image_paths:
        image = Image.open(img_path)
        image = preprocess(image).unsqueeze(0).to(device)
        with torch.no_grad():
            image_feature = model.encode_image(image)
            image_features.append(image_feature)
    return torch.cat(image_features, dim=0)

train_features = encode_images(train_images).cpu().numpy()
test_features = encode_images(test_images).cpu().numpy()

log_reg = LogisticRegression()
gb = GradientBoostingClassifier()
nb = GaussianNB()


knn = KNeighborsClassifier()
svm = SVC(probability=True)
rf = RandomForestClassifier()

knn_param_grid = {'n_neighbors': [3, 5, 7, 9], 'metric': ['euclidean', 'manhattan']}
svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}
gb_param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]}

knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring='accuracy', verbose=1)
svm_grid_search = GridSearchCV(SVC(probability=True), svm_param_grid, cv=5, scoring='accuracy', verbose=1)
rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='accuracy', verbose=1)
gb_grid_search = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=5, scoring='accuracy', verbose=1)

knn_grid_search.fit(train_features, train_labels)
svm_grid_search.fit(train_features, train_labels)
rf_grid_search.fit(train_features, train_labels)
gb_grid_search.fit(train_features, train_labels)

best_knn = knn_grid_search.best_estimator_
best_svm = svm_grid_search.best_estimator_
best_rf = rf_grid_search.best_estimator_
best_gb = gb_grid_search.best_estimator_

print(f"Best KNN parameters: {knn_grid_search.best_params_}")
print(f"Best SVM parameters: {svm_grid_search.best_params_}")
print(f"Best Random Forest parameters: {rf_grid_search.best_params_}")
print(f"Best Gradient Boosting parameters: {gb_grid_search.best_params_}")

voting_clf = VotingClassifier(
    estimators=[
        ('knn', best_knn),
        ('svm', best_svm),
        ('rf', best_rf),
        ('log_reg', log_reg),
        ('gb', best_gb),
        ('nb', nb)
    ],
    voting='soft'
)


voting_clf.fit(train_features, train_labels)

predicted_labels = voting_clf.predict(test_features)

accuracy = accuracy_score(test_labels, predicted_labels)
print(f"Test accuracy (ensemble classifier with soft voting and more classifiers): {accuracy * 100:.2f}%")

conf_matrix = confusion_matrix(test_labels, predicted_labels)
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Mild", "Severe"], yticklabels=["Mild", "Severe"])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix (Ensemble Classifier with Soft Voting and More Classifiers)')
plt.show()

print("Classification Report (Ensemble Model):")
print(classification_report(test_labels, predicted_labels, target_names=["Mild", "Severe"]))

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

meta_classifier = LogisticRegression()

stacking_clf = StackingClassifier(
    estimators=[
        ('knn', best_knn),
        ('svm', best_svm),
        ('rf', best_rf),
        ('gb', best_gb),
        ('nb', nb)
    ],
    final_estimator=meta_classifier,
    cv=5
)

stacking_clf.fit(train_features, train_labels)
total_end_time_2 = time.time()

predicted_labels = stacking_clf.predict(test_features)

print("Classification Report (Stacking Classifier):")
print(classification_report(test_labels, predicted_labels, target_names=["Mild", "Severe"]))

