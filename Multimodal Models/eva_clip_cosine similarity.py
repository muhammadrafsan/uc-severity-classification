# -*- coding: utf-8 -*-
"""EVA_CLIP_with_Text_Feature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mSPlx_idB0C2SobE3AU4exLgHfSrRHeF
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/baaivision/EVA.git
# %cd EVA/EVA-CLIP

!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

!pip install timm ftfy opt-einsum

!pip install xformers

!pip install git+https://github.com/NVIDIA/apex.git

import sys
sys.path.append('/content/EVA/EVA-CLIP/rei')

import torch
from eva_clip import create_model_and_transforms, get_tokenizer
model_name = "EVA02-CLIP-B-16"

model, _, preprocess = create_model_and_transforms(model_name, pretrained='eva_clip', force_custom_clip=True)
tokenizer = get_tokenizer(model_name)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# Provided text descriptions
class_descriptions_split = [
    [
        "Mild Ulcerative Colitis: The colon appears relatively healthy with a reddish or pinkish hue, indicating low-grade inflammation.",
        "The mucosal surface is generally smooth, with a visible vascular pattern. Small superficial erosions may be present, but ulcerations are shallow and scattered.",
        "There is little to no bleeding, and the overall appearance reflects minimal damage confined to the mucosa."
    ],
    [
        "Severe Ulcerative Colitis: The colon takes on a deep red or purplish color, indicating severe inflammation.",
        "The surface is irregular, with prominent ulcerations that span large areas and reach deeper layers of the colon.",
        "Blood vessels are no longer visible due to thickened tissue, and bleeding often occurs spontaneously or upon contact."
    ]
]

mild_text = " ".join(class_descriptions_split[0])
severe_text = " ".join(class_descriptions_split[1])

text_tokens_mild = tokenizer([mild_text])
text_tokens_severe = tokenizer([severe_text])

text_inputs_mild = text_tokens_mild.to(device)
text_inputs_severe = text_tokens_severe.to(device)

with torch.no_grad():
    text_features_mild = model.encode_text(text_inputs_mild)
    text_features_severe = model.encode_text(text_inputs_severe)

text_features_mild /= text_features_mild.norm(dim=-1, keepdim=True)
text_features_severe /= text_features_severe.norm(dim=-1, keepdim=True)

print("Text features for mild and severe classes are encoded and normalized.")

from google.colab import drive
drive.mount('/content/drive')

import os
from sklearn.model_selection import train_test_split

dataset_dir = "/content/drive/MyDrive/Binary Ulceraive Colitis"
mild_images_dir = os.path.join(dataset_dir, "mild")
severe_images_dir = os.path.join(dataset_dir, "severe")

print("Mild directory exists:", os.path.exists(mild_images_dir))
print("Severe directory exists:", os.path.exists(severe_images_dir))

mild_images = [os.path.join(mild_images_dir, img) for img in os.listdir(mild_images_dir) if img.endswith('.jpg')]
severe_images = [os.path.join(severe_images_dir, img) for img in os.listdir(severe_images_dir) if img.endswith('.jpg')]

print(f"Number of mild images found: {len(mild_images)}")
print(f"Number of severe images found: {len(severe_images)}")

all_images = mild_images + severe_images
labels = [0] * len(mild_images) + [1] * len(severe_images)

train_images, test_images, train_labels, test_labels = train_test_split(all_images, labels, test_size=0.2, stratify=labels, random_state=42)

print(f"Training set: {len(train_images)} images")
print(f"Testing set: {len(test_images)} images")

from PIL import Image
import torch

def encode_images(image_paths):
    image_features = []

    for img_path in image_paths:
        image = Image.open(img_path)
        image = preprocess(image).unsqueeze(0).to(device)

        with torch.no_grad():
            image_feature = model.encode_image(image)
            image_features.append(image_feature)

    image_features = torch.cat(image_features, dim=0)

    return image_features

train_images_mild = [img for img, label in zip(train_images, train_labels) if label == 0]
train_images_severe = [img for img, label in zip(train_images, train_labels) if label == 1]

print("Encoding mild images...")
mild_image_features = encode_images(train_images_mild)

print("Encoding severe images...")
severe_image_features = encode_images(train_images_severe)

avg_mild_features = mild_image_features.mean(dim=0)
avg_severe_features = severe_image_features.mean(dim=0)

avg_mild_features /= avg_mild_features.norm(dim=-1, keepdim=True)
avg_severe_features /= avg_severe_features.norm(dim=-1, keepdim=True)

print("Average image features for both classes are computed and normalized.")

from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt



from torch.nn.functional import cosine_similarity

def classify_image_cosine_similarity(image_path, avg_mild_features, avg_severe_features):
    image = Image.open(image_path)
    image = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        image_feature = model.encode_image(image)
    image_feature /= image_feature.norm(dim=-1, keepdim=True)
    similarity_mild = cosine_similarity(image_feature, avg_mild_features, dim=-1)
    similarity_severe = cosine_similarity(image_feature, avg_severe_features, dim=-1)
    return 0 if similarity_mild > similarity_severe else 1

print("Classification function using cosine similarity is ready.")

predicted_labels = []
for img_path in test_images:
    predicted_label = classify_image_cosine_similarity(img_path, avg_mild_features, avg_severe_features)
    predicted_labels.append(predicted_label)

accuracy = accuracy_score(test_labels, predicted_labels)
print(f"Test accuracy: {accuracy * 100:.2f}%")

conf_matrix = confusion_matrix(test_labels, predicted_labels)
plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Mild", "Severe"], yticklabels=["Mild", "Severe"])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

